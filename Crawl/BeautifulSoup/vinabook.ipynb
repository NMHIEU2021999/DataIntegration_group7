{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\thinkpro\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# !pip install --quiet bs4\n",
    "from bs4 import BeautifulSoup \n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(1,1000):\n",
    "    print(i)\n",
    "    try:\n",
    "        stri = f'https://www.fahasa.com/all-category.html?order=num_orders&limit=24&p={i}'\n",
    "        source = requests.get(stri, headers={\n",
    "        \"User-Agent\" : \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36\"\n",
    "        }).text\n",
    "        soup = BeautifulSoup(source, 'lxml')\n",
    "\n",
    "        a = soup.find('ul', id='products_grid', class_='products-grid fhs-top')\n",
    "        b = a.find_all('li')\n",
    "        for i in b:\n",
    "            try:\n",
    "                url = str(i).split('href=\"')[1].split('\" title')[0]\n",
    "                source = requests.get(url, headers={\n",
    "                \"User-Agent\" : \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36\"\n",
    "                }).text\n",
    "                soup_1 = BeautifulSoup(source, 'lxml')\n",
    "\n",
    "                image_url = str(soup_1.find('div', class_='product-view-image-product').img).split('data-src=\"')[1].split('\" id=\"image\"')[0]\n",
    "\n",
    "                name = str(soup_1.find('div', class_='product-view-image-product').img).split('\" class')[0].split('<img alt=\"')[1]\n",
    "\n",
    "                tag_price = soup_1.find('div', class_='col-md-12 price-block').find('div', class_='price-box').find_all('p')\n",
    "                if len(tag_price) == 2:\n",
    "                    price = str(soup_1.find('div', class_='col-md-12 price-block').find('div', class_='price-box').find_all('p')[1].find_all('span')[1]).split('\\xa0')[0].split('>')[1]\n",
    "                if len(tag_price) == 1:\n",
    "                    price = str(soup_1.find('div', class_='col-md-12 price-block').find('div', class_='price-box').find_all('p')[0].find_all('span')[1]).split('\\xa0')[0].split('>')[1]\n",
    "\n",
    "                len_author = len(str(soup_1.find_all('table', class_='data-table table-additional')).split('class=\"data_author\">\\n\\t\\t\\t\\t    '))\n",
    "                if len_author == 1:\n",
    "                    author_name = 'NULL'\n",
    "                if len_author > 1:\n",
    "                    author_name = str(soup_1.find_all('table', class_='data-table table-additional')).split('class=\"data_author\">\\n\\t\\t\\t\\t    ')[1].split('\\t')[0]\n",
    "\n",
    "                provider = str(soup_1.find_all('table', class_='data-table table-additional')).split('ATTRIBUTE_PRODUCT\">')[2].split('<')[0]\n",
    "                publisher = str(soup_1.find_all('table', class_='data-table table-additional')).split('publisher\">\\n\\t\\t\\t\\t    ')[1].split('\\t')[0]\n",
    "                num_page = str(soup_1.find_all('table', class_='data-table table-additional')).split('class=\"data_qty_of_page\">\\n\\t\\t\\t\\t    ')[1].split('\\t')[0]\n",
    "                cover_type = str(soup_1.find_all('table', class_='data-table table-additional')).split('class=\"data_book_layout\">\\n\\t\\t\\t\\t    ')[1].split('\\t')[0]\n",
    "                size = str(soup_1.find_all('table', class_='data-table table-additional')).split('data_size\">\\n\\t\\t\\t\\t    ')[1].split('\\t')[0]\n",
    "                release_year = str(soup_1.find_all('table', class_='data-table table-additional')).split('class=\"data_publish_year\">\\n\\t\\t\\t\\t    ')[1].split('\\t')[0]\n",
    "                store.append((url, image_url, name, author_name, price, provider, publisher, num_page, cover_type, size, release_year))\n",
    "            except:\n",
    "                continue\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = ['url', 'image_url', 'author_name', 'name', 'price', 'provider', 'publisher', 'num_page', 'cover_type', 'size', 'release_year']\n",
    "df = pd.DataFrame.from_records(store, columns=column_name)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('vinabook.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1172ab68b0adc78e3697dca12a3cf5a2c3d72cf50b429f588e28ed10d69249ca"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
